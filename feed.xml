<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://abcsofdatascience.ca/feed.xml" rel="self" type="application/atom+xml" /><link href="https://abcsofdatascience.ca/" rel="alternate" type="text/html" /><updated>2020-03-30T10:54:44-05:00</updated><id>https://abcsofdatascience.ca/feed.xml</id><title type="html">ABCs of data science</title><subtitle>A gentle introduction to many data science concepts for readers of all backgrounds</subtitle><entry><title type="html">C is for Clustering</title><link href="https://abcsofdatascience.ca/blog/c-is-for-clustering" rel="alternate" type="text/html" title="C is for Clustering" /><published>2020-03-01T00:00:00-06:00</published><updated>2020-03-01T00:00:00-06:00</updated><id>https://abcsofdatascience.ca/blog/c-is-for-clustering</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/c-is-for-clustering">&lt;p&gt;Clustering is useful when you want to find groups of related items. For example, these items could be documents, malware samples, or customers. Clustering is also referred to as unsupervised learning since it does not involve labelled data. High quality labelled data is often hard to get, so clustering is often a good method to analyze your data. We often use clustering methods (along with visualization) when doing exploratory data analysis (EDA) since it allows us to understand how the data clumps together.&lt;/p&gt;

&lt;h3 id=&quot;what-else-can-you-use-clustering-for&quot;&gt;What else can you use clustering for?&lt;/h3&gt;

&lt;h5 id=&quot;anomalyoutlier-detection&quot;&gt;Anomaly/outlier detection&lt;/h5&gt;
&lt;p&gt;Since you know which group an object belongs to, you can say “show me the items which don’t belong to a group”. You can also look for points on the outer edges of clusters since they may also be anomalous.&lt;/p&gt;

&lt;h5 id=&quot;labelling-points&quot;&gt;Labelling points&lt;/h5&gt;

&lt;p&gt;You can even use clustering to help you label your data! Instead of labelling 100 images as dogs/cats individually, you could have groups of images which are much easier to label (i.e. “here are 24 dogs all grouped together”).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/dogs_and_cats_labels.png&quot; alt=&quot;&quot; title=&quot;Is this just an excuse to post cute animal pictures? Maybe.&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-do-you-actually-cluster-points-together&quot;&gt;How do you actually cluster points together?&lt;/h3&gt;

&lt;p&gt;Take a look at the image below (courtesy of &lt;a href=&quot;https://twitter.com/leland_mcinnes&quot;&gt;Leland Mcinnes&lt;/a&gt;). You can probably see which points should be grouped together but some points clearly look like they don’t belong to any groups.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/comparing_clustering_algorithms_unclustered.png&quot; alt=&quot;&quot; title=&quot;Taken from https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The simple definition of clustering “find similar groups of stuff” sounds fairly simple at the surface. If you think about it a bit more you’ll realize that there are a number of questions that need to be answered:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;How do you define similarity?&lt;/em&gt; In every clustering algorithm you need to specify a way of measuring the distance between two points. This is often referred to as a &lt;strong&gt;distance metric&lt;/strong&gt;. As you would expect, points are similar if they are close together (the distance between them is small) and less similar the farther apart they are. There are many kinds of distance metrics, which I will touch on in later blog posts.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Does every point need to belong to a group? Can a point belong to multiple groups?&lt;/em&gt; The answers to these questions depend on the algorithm. In some cases, points can only belong to one group. This is known as &lt;strong&gt;hard clustering&lt;/strong&gt;. In other cases they have a probability associated with being part of a cluster. This is known as &lt;strong&gt;soft clustering&lt;/strong&gt; (or fuzzy clustering). Some clustering algorithms will force every point into a group (whether it belongs in there or not), while others will just label those points as outliers/noise.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;types-of-clustering-methods&quot;&gt;Types of clustering methods&lt;/h3&gt;

&lt;p&gt;Since the definition of cluster is so broad, there are many types of clustering algorithms. Here are a few broad categories:&lt;/p&gt;

&lt;h5 id=&quot;centroid-based&quot;&gt;Centroid based&lt;/h5&gt;

&lt;p&gt;In these algorithms, clusters are determined based on which centroid you are closest to. A centroid is just a point calculated by averaging all of the other points in a group. One popular centroid based method is k-means which works as follows.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pick &lt;em&gt;k&lt;/em&gt; centroids (where k is the number of clusters in your data). For the sake of argument, let’s say we have 2 centroids.&lt;/li&gt;
  &lt;li&gt;Randomly place the centroids&lt;/li&gt;
  &lt;li&gt;Calculate the distance from each point to the centroid, and pick the closest centroid as its cluster id. For example if a point is closest to centroid 1 then it is part of cluster 1&lt;/li&gt;
  &lt;li&gt;Recalculate the centroids as the average of all of the points in the cluster. Centroid 1 is now the average of all points in cluster 1, centroid 2 the average of all points in cluster 2, etc.&lt;/li&gt;
  &lt;li&gt;Repeat steps 3 and 4 until your clusters stabilize (i.e. the cluster ids for your points stop changing)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/kmeansViz.png&quot; alt=&quot;&quot; title=&quot;Taken from https://stanford.edu/~cpiech/cs221/img/kmeansViz.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are a few issues with this method. The first is that it is really hard to know how many clusters you have ahead of time (i.e it’s hard to choose k). The second is that it doesn’t allow for clusters of different shapes since it assumes that all clusters are spherical. Finally, every point is forced into a cluster.&lt;/p&gt;

&lt;h5 id=&quot;density-based&quot;&gt;Density based&lt;/h5&gt;

&lt;p&gt;In density based clustering algorithms, clusters are areas with lots of points. If you look at the image above, this probably closely aligns with your intuition about what is/is not in a cluster. The clusters you identified have high density (lots of points in a small area). &lt;a href=&quot;(https://en.wikipedia.org/wiki/DBSCAN)&quot;&gt;DBSCAN&lt;/a&gt; (density-based spatial clustering of applications with noise) is a popular density based clustering algorithm. It has two main parameters, min_points and epsilon. In order for something to be labelled a cluster, there must be at least min_points close together. If min_points is 10, that means there will be no clusters with less than 10 data points. Epsilon is basically “how far from a point do I look to see if it is close”. For each point, you can see how many other points are within epsilon. If there are at least min_points, then you have a cluster. In the image below, all of the red points (A) have at least 4 points (min_points=4) within epsilon distance. The yellow points (B and C) are also in the cluster because they are reachable from one of the red points. N would be labelled an outlier since it is not within epsilon of any points.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/600px-DBSCAN-Illustration.svg.png&quot; alt=&quot;&quot; title=&quot;Taken from https://en.wikipedia.org/wiki/File:DBSCAN-Illustration.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Choosing min_points is much easier than choosing the number of clusters ahead of time (which we needed to do in k-means). However, picking the correct value for epsilon can be tricky and is more of an art than a science. Another issue with DBSCAN is that it assumes all of the clusters have the same density, which is not always the case.&lt;/p&gt;

&lt;h5 id=&quot;distribution-based&quot;&gt;Distribution based&lt;/h5&gt;

&lt;p&gt;In these algorithms, you train sets of statistical models and points are assigned to a cluster based on which model they are most likely to occur in. One benefit of this type of algorithm is each point has a probability associated with belonging (e.g. 0.75 probability of being in cluster A, and a 0.25 probability of being in cluster B). This means soft clustering is baked into the algorithm, and if you want hard clusters (i.e. a point can only belong to one cluster) you can just choose the largest likelihood. One popular algorithm in this class is Gaussian Mixture Models, where you start with a set of randomly initialized Gaussian models and then update their parameters based on your data. Learning these parameters is done using an interative method called [expectation-maximization algorithm(https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm). One downside of these types of models is that they may overfit your data. That is the model will fit your data very well but not generalize well to new data.&lt;/p&gt;

&lt;h5 id=&quot;connectivity-based&quot;&gt;Connectivity based&lt;/h5&gt;

&lt;p&gt;Connectivity based clustering is also known as hierarchical clustering. One of the core ideas is that things can be grouped together at different levels. For example a picture of a golden retriever could be grouped with other retriever breeds, all dogs, common pets, all animals, etc. In this case other pictures of retrievers would be close, other dogs slightly further away, and then other animals further away from that. This creates a dendrogram (tree) and the clusters are determined by where you cut in the tree. For example in the figure if you cut at the first branch, you would have two clusters: one containing lemurs, and the other containing all of the pictures of cats/dogs. Cutting at the next branch down you would have three clusters: lemurs, cats, and all dogs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/hierarchical_clustering.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are basically two ways to create this dendrogram. The first is a bottom up approach where every point starts as its own cluster and then you merge clusters together. In the second method everything starts as its own cluster and then you iteratively break everything apart until each point is it’s own cluster. The difference between algorithms in this class basically differ on how you choose to measure the distance between clusters.&lt;/p&gt;

&lt;h3 id=&quot;how-do-i-choose-which-clustering-or-class-of-algorithm-to-use&quot;&gt;How do I choose which clustering (or class of) algorithm to use?&lt;/h3&gt;

&lt;p&gt;Some of this depends on your data. In practice many algorithms combine elements of these classes. One example of this is &lt;a href=&quot;https://hdbscan.readthedocs.io/en/latest/&quot;&gt;HDBSCAN&lt;/a&gt; (hierarchical DBSCAN), which is an extremely useful clustering algorithm. I’ll talk about HDBSCAN in more detail in a future blog post but HDBSCAN is a good first choice. If you’re looking for a comparison of different clustering algorithms on the sample data I showed above, take a look at the link “Comparing clustering algorithms” in the resources below.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html&quot;&gt;Comparing clustering algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ayZQj4llUSU&quot;&gt;Clustering: a guide for the perplexed&lt;/a&gt; - John Healy and Leland Mcinnes&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=JnnaDNNb380&amp;amp;list=PL8dPuuaLjXtO65LeD2p4_Sb5XQ51par_b&amp;amp;index=7&quot;&gt;Crash course AI: unsupervised learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Clustering is useful when you want to find groups of related items. For example, these items could be documents, malware samples, or customers. Clustering is also referred to as unsupervised learning since it does not involve labelled data. High quality labelled data is often hard to get, so clustering is often a good method to analyze your data. We often use clustering methods (along with visualization) when doing exploratory data analysis (EDA) since it allows us to understand how the data clumps together.</summary></entry><entry><title type="html">B is for Bias</title><link href="https://abcsofdatascience.ca/blog/b-is-for-bias" rel="alternate" type="text/html" title="B is for Bias" /><published>2020-02-01T00:00:00-06:00</published><updated>2020-02-01T00:00:00-06:00</updated><id>https://abcsofdatascience.ca/blog/b-is-for-bias</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/b-is-for-bias">&lt;p&gt;The term bias is used in a few different contexts within data science. When people mention bias they are typically referring to either the “bias-variance tradeoff” or “unjust bias”. I’ll primarily talk about unjust bias in this blog and will talk about tuning models/measuring model performance in later blogs.&lt;/p&gt;

&lt;h3 id=&quot;bias-variance-tradeoff&quot;&gt;Bias-variance tradeoff&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff&quot;&gt;bias-variance tradeoff&lt;/a&gt; refers to tuning models such that they don’t under/overfit your data. A model has high bias if it underfits the training set (e.g. if you are trying to fit a line to non-linear data). A model has high variance if it overfits the training set (i.e. doesn’t generalize well). This could occur if you have a huge non-linear function with a large number of parameters. The bias-variance tradeoff is trying to find a model that minimizes both of these phenomena.&lt;/p&gt;

&lt;h3 id=&quot;unjust-bias-and-the-importance-of-having-a-human-in-the-loop&quot;&gt;Unjust bias and the importance of having a human in the loop&lt;/h3&gt;

&lt;p&gt;Machine learning models are useful for helping humans sort through large piles of data. However, it is critical to have a human in the loop in order to validate predictions. It’s particularly important when ML models are used to predict things like university admissions or welfare benefits which have a huge impact on people’s lives. As we talked about in the previous blog, there are two key points to always keep in mind about AI/ML&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It’s not magic&lt;/li&gt;
  &lt;li&gt;It’s not perfect&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Problems arise when people treat the output of ML models as completely objective (or magic) with no opportunities to overrule these predictions.&lt;/p&gt;

&lt;p&gt;Bias refers to a model that is prejudiced in favour of particular categories. Unjust bias occurs when there is a mismatch between the models view of the world and how we think the world should be. There are many reasons that this can happen but two of the big ones are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The training data is not truly representative. It may favour certain categories over others leading to better predictions on those categories. As the saying goes: “garbage in, garbage out”.&lt;/li&gt;
  &lt;li&gt;The training data is truly representative of past behaviour. However, this might be different than what we want the future behaviour to be.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are a couple of famous examples of biased models which demonstrate this behaviour.&lt;/p&gt;

&lt;h3 id=&quot;facial-recognition&quot;&gt;Facial recognition&lt;/h3&gt;

&lt;p&gt;Facial recognition tools are increasingly being utilized by organizations such as law enforcement agencies. Model fairness is critical in this case since if a model is biased against particular subgroups it will have a disproportionate impact on the lives of people in that subgroup.
Researchers studied 3 commercially available facial recognition tools from Microsoft, IBM, and FACE++ (study is &lt;a href=&quot;http://gendershades.org/&quot;&gt;here&lt;/a&gt;). The researchers found that the models performed much better on men and also had higher accuracy on lighter skinned people. In the worst case there was a 34.4% difference in accuracy between lighter skinned men compared to darker skinned women. This shows when the training data does not accurately represent all subgroups the result is a biased model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/b_is_for_bias/gendershades.png&quot; alt=&quot;&quot; title=&quot;Taken from http://gendershages.org&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;amazons-hiring-model&quot;&gt;Amazon’s hiring model&lt;/h3&gt;

&lt;p&gt;Like many companies, Amazon receives huge numbers of applicants and sorting through these applications is incredibly time intensive. They had a historical set of applications and know which of those candidates were hired. So, they developed a machine learning model to sort through the applications and rank the candidates in terms of their likelihood to be hired. However, this essentially turned into a gender detection model since the vast majority of their previous hires were men. For example, the model would penalize resumes which included the word “women’s”. This is a case where a model can make accurate predictions based on historical data, however this does not match with how hiring should be done. Despite the fact that Amazon scrapped this model, they are far from the only company who would like to automate portions of their hiring process. Creating a fair and unbiased method of doing so that is interpretable is still an open research question. You should be suspicious of anyone who claims to have solved this problem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://imgs.xkcd.com/comics/ai_hiring_algorithm.png&quot; alt=&quot;&quot; title=&quot;So glad Kate over in R&amp;amp;D pushed for using the AlgoMaxAnalyzer to look into this. Hiring her was a great decisio- waaaait.&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-can-we-fix-this&quot;&gt;How can we fix this?&lt;/h3&gt;

&lt;p&gt;It is important to note that &lt;strong&gt;humans are also biased&lt;/strong&gt;. They can grade using different criteria if they get grumpy or tired. The appeal of using ML models is that they are much cheaper than humans and can scale much better. If left unchecked, this just means that biased decisions are made at a much larger scale than what was done previously. The best approach is to use a mixture of ML models while keeping a human in the loop. This means providing a way for people to appeal decisions made by an ML model (such as university/college admissions) and allowing a human to override the decision. As researchers, something to keep in mind is that the users of these algorithms may not understand probabilities/confidence intervals. Even if they do understand these concepts they may not feel comfortable overruling the ML model.&lt;/p&gt;

&lt;p&gt;Creating models that are fair and interpretable is still an active area of research. This is an incredibly complex and nuanced topic but it is important to be aware of it. Later on, I will write a blog about the different techniques you can use to interpret ML models to try and gain insight into how they are making decisions.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=S-6YGPrmtYc&quot;&gt;Getting Specific About Algorithmic Bias&lt;/a&gt;) - &lt;a href=&quot;https://twitter.com/math_rachel&quot;&gt;Rachel Thomas&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.ca/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815&quot;&gt;Weapons of Math Destruction&lt;/a&gt; - &lt;a href=&quot;https://twitter.com/mathbabedotorg&quot;&gt;Cathy O’Neil&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.ca/Hello-World-Algorithms-Define-Future/dp/039363499X&quot;&gt;Hello World&lt;/a&gt; - &lt;a href=&quot;https://twitter.com/fryrsquared&quot;&gt;Hannah Fry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">The term bias is used in a few different contexts within data science. When people mention bias they are typically referring to either the “bias-variance tradeoff” or “unjust bias”. I’ll primarily talk about unjust bias in this blog and will talk about tuning models/measuring model performance in later blogs.</summary></entry><entry><title type="html">A is for Artificial Intelligence</title><link href="https://abcsofdatascience.ca/blog/a-is-for-ai" rel="alternate" type="text/html" title="A is for Artificial Intelligence" /><published>2020-01-15T00:00:00-06:00</published><updated>2020-01-15T00:00:00-06:00</updated><id>https://abcsofdatascience.ca/blog/a-is-for-ai</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/a-is-for-ai">&lt;p&gt;I was recently in San Francisco and throughout the city there are many, many billboards containing slogans like “Mission Critical AI” and “Enterprise AI”. There is no doubt that usage of the phrase “artificial intelligence” or AI has increased dramatically in recent years. This increased usage has made it difficult to tell what “using AI” even means.&lt;/p&gt;

&lt;h3 id=&quot;so-what-is-ai&quot;&gt;So what is AI?&lt;/h3&gt;

&lt;p&gt;Many people have differing opinions on how to strictly define AI. When people refer to AI this is generally synonymous with machine learning (ML). Since it’s so hard to come up with a definition, let’s define what AI is not:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;AI is not magic&lt;/li&gt;
  &lt;li&gt;AI is not perfect (more on that in B is for Bias)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It’s hard to come up with a strict definition for AI since the generally agreed upon definition has evolved over time. In the 1980s people called large rule based systems (“expert systems”) AI. These systems required subject matter experts and programmers to define a set of rules. As you can imagine (or remember) this is a very time intensive process and there are lots of edge cases to consider. Nowadays people typically think of deep learning (more on that in D is for Deep Learning) as AI. This requires lots of labeled training data (which often needs to be labeled by experts) but models can learn their own rules about the data.&lt;/p&gt;

&lt;p&gt;In both cases the “intelligence” part of AI is a bit of a misnomer. Another term that has been suggested  is &lt;a href=&quot;https://twitter.com/fchollet/status/1214392496375025664&quot;&gt;“cognitive automation”&lt;/a&gt;. We are trying to teach a machine to perform a set of tasks based on our knowledge of the world. This is different from something that is truly intelligent that can reason about the world and learn abstract concepts. This distinction is important and referred to as “general” versus “narrow” AI.&lt;/p&gt;

&lt;p&gt;General AI (also referred to as strong AI) refers to a machine that is “human-like” (think HAL 9000 or Skynet). As you would expect from the name, it can generalize it’s previous knowledge to new problem domains. This means that It can intelligently perform a wide variety of tasks without needing explicit training data. Voice assistants like Alexa, and Siri seem like they can generalize, but as anyone who has used them knows, they definitely have limits. They tend not to understand context in a way that a human would, and questions may need to be rephrased in order to be interpreted correctly. A true general AI doesn’t currently exist and it will probably be a while before it does.&lt;/p&gt;

&lt;p&gt;Narrow AI (or weak AI) refers to a machine that is good at specific tasks (e.g. image recognition) but can’t generalize to different domains. For example, you could train a machine learning model to distinguish between cats and dogs but it would not be able to answer the question “Where is the best pizza in Ottawa?”. Narrow AI works by using predefined rules or learning from lots of (probably labelled) data.&lt;/p&gt;

&lt;h3 id=&quot;what-is-ai-used-for&quot;&gt;What is AI used for?&lt;/h3&gt;

&lt;p&gt;AI/ML is widely used in a large variety of industries for a number of tasks. This includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recommending videos on youtube&lt;/li&gt;
  &lt;li&gt;Detecting if a computer has malware&lt;/li&gt;
  &lt;li&gt;Financial trading&lt;/li&gt;
  &lt;li&gt;Helping doctors make diagnoses&lt;/li&gt;
  &lt;li&gt;Voice assistants like Google Assistant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many of these tasks are applications of fields such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computer vision (processing images and audio)&lt;/li&gt;
  &lt;li&gt;Natural Language Processing (NLP)&lt;/li&gt;
  &lt;li&gt;Recommender systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The fact that AI is a buzzword means that it is applied to many different products (even if they don’t include any ML models). This over usage of the term causes many people to twitch when they hear it (and judge people who do use the term). However, it’s important to keep in mind your audience when you are talking about machine learning. Some audiences may not be familiar with specific technical terms (point them at this blog series ;) ) but have heard the term AI.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;AI/ML is a rapidly growing field which is being applied to a large variety of domains. It’s hard to separate what is real from the snake oil. I’m hoping this blog series will give you enough background knowledge to think critically when you hear the term AI and know the limitations of AI/ML models. In the next blog I’ll talk about many of these limitations and how they affect people’s everyday lives.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PL8dPuuaLjXtO65LeD2p4_Sb5XQ51par_b&quot;&gt;Crash Course Artificial Intelligence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.ca/Hello-World-Algorithms-Define-Future/dp/039363499X&quot;&gt;Hello World&lt;/a&gt; - &lt;a href=&quot;https://twitter.com/fryrsquared&quot;&gt;Hannah Fry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">I was recently in San Francisco and throughout the city there are many, many billboards containing slogans like “Mission Critical AI” and “Enterprise AI”. There is no doubt that usage of the phrase “artificial intelligence” or AI has increased dramatically in recent years. This increased usage has made it difficult to tell what “using AI” even means.</summary></entry></feed>