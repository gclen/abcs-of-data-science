<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://abcsofdatascience.ca/feed.xml" rel="self" type="application/atom+xml" /><link href="https://abcsofdatascience.ca/" rel="alternate" type="text/html" /><updated>2020-05-30T15:49:15-05:00</updated><id>https://abcsofdatascience.ca/feed.xml</id><title type="html">ABCs of data science</title><subtitle>A gentle introduction to many data science concepts for readers of all backgrounds</subtitle><entry><title type="html">G is for Gradient Descent</title><link href="https://abcsofdatascience.ca/blog/g-is-for-gradient-descent" rel="alternate" type="text/html" title="G is for Gradient Descent" /><published>2020-05-30T00:00:00-05:00</published><updated>2020-05-30T00:00:00-05:00</updated><id>https://abcsofdatascience.ca/blog/g-is-for-gradient-descent</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/g-is-for-gradient-descent">&lt;p&gt;As I’ve said many times before AI/machine learning/deep learning is &lt;a href=&quot;https://abcsofdatascience.ca/blog/a-is-for-ai&quot;&gt;not magic&lt;/a&gt;. In the case of supervised learning models (including &lt;a href=&quot;https://abcsofdatascience.ca/blog/d-is-for-deep-learning&quot;&gt;deep learning&lt;/a&gt;) you have four things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Labelled data&lt;/li&gt;
  &lt;li&gt;Features (e.g. image pixels or text)&lt;/li&gt;
  &lt;li&gt;A weight for each feature (since some features are more important than others)&lt;/li&gt;
  &lt;li&gt;An objective (or cost) function which measures how well/poorly your predictions match the labels.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Before we start training a model, we have our data set and choose the features we want to use, as well as an objective function. I’ve mentioned some common objective functions in previous blog posts including cross-entropy loss and root mean squared error (RMSE). An objective function is a function of both the features as well as the weights. Once we’ve chosen the features and objective function, they are fixed while we actually train the model. This means the only thing we can change is the weight of each feature. When we refer to training a model, what we typically mean is finding which values of weights &lt;strong&gt;minimize or maximize&lt;/strong&gt; the objective function. How do we actually find this set of weights? You can imagine trying a bunch of different sets of weights and seeing which gives the best model performance. However, as you might expect there are better ways to find the best set of weights. The broad category of algorithms that find the minimum/maximum values of functions are called &lt;strong&gt;optimization methods&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;gradient-descent&quot;&gt;Gradient descent&lt;/h3&gt;

&lt;p&gt;Gradient descent (and related variants) is a popular optimization technique and it is widely used in a variety of applications, including basically all deep learning models. It is an &lt;strong&gt;iterative&lt;/strong&gt; method, which means it keeps repeating the same steps until some criteria is reached. This stopping criteria is also referred to as &lt;strong&gt;convergence criteria&lt;/strong&gt;. This stopping condition could be “stop when the value of the loss function doesn’t change from step to step”. Let’s imagine we have a simple loss function like the one shown below and our starting position is shown in red. This starting position is typically random, since our weights are randomly initialized. We want to figure out how to get to the bottom of this bowl shaped curve, since this is the set of parameters where our loss function is at the smallest value. As we iterate through this process, we are “learning” better sets of parameters (or weights).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/g_is_for_gradient_descent/loss_function.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Imagine that you are on a hill at this red dot, and need to get to the bottom of the valley. However, you are also blindfolded (which sounds like the world’s worst escape room) so you can’t see where the valley is. You also want to get to the bottom of the hill as quickly as possible, so you want to take as few steps as possible. How would you do this? You would probably try to find the direction where the hill is the steepest and take a step in that direction. You would keep repeating this process until you got to the bottom of the hill. This is exactly what gradient descent is doing. We can calculate the direction with the steepest slope by calculating the derivative (or gradient) of the loss function. We then take a step in that direction, then keep repeating the process until we reach some stopping criteria.&lt;/p&gt;

&lt;p&gt;The key parameter in gradient descent is called the &lt;strong&gt;step size&lt;/strong&gt; or &lt;strong&gt;learning rate&lt;/strong&gt; which says how far to step in the direction of the gradient. It is really important to choose this value correctly. If we choose an appropriate value (like the one shown below) we can take a reasonable number of steps (in this case 7) to get to the bottom of the hill.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/g_is_for_gradient_descent/gradient_descent_optimal.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;However, if we make the learning rate too small, then we need to take a lot of steps and this means that it takes much longer to get to the bottom of the hill.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/g_is_for_gradient_descent/gradient_descent_small_step_size.png&quot; alt=&quot;&quot; title=&quot;Here the learning rate is too small&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If we make it larger, then we can take fewer steps. But this also runs the risk of overshooting the minimum and even risks not converging at all.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/g_is_for_gradient_descent/gradient_descent_too_large.png&quot; alt=&quot;&quot; title=&quot;Here the learning rate is too large&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One way around this problem of having to choose the best learning rate is called “learning rate annealing”. Basically, it means that we start with a large learning rate (so we can quickly take large steps in the right direction). As we continue, we start taking smaller and smaller steps, so that we don’t overshoot the minimum. This has a nice balance between the large and small step sizes which makes choosing an initial learning rate less tricky.&lt;/p&gt;

&lt;h3 id=&quot;local-vs-global-minima&quot;&gt;Local vs global minima&lt;/h3&gt;

&lt;p&gt;Up until now, we have been talking about a very simple loss function which only has one minimum. In practice, loss functions are very messy and have many hills and valleys. Each valley has a &lt;strong&gt;local minima&lt;/strong&gt; and there is one true &lt;strong&gt;global minimum&lt;/strong&gt; which is actually the lowest point. In the loss function shown below, there are two minima. If we start at the red dot and use the method described above, we will get stuck in the valley on the right (a local minimum). However, we would like to get to the bottom of the valley on the left.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/g_is_for_gradient_descent/loss_function_local_minima.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One technique for doing this is called &lt;strong&gt;gradient descent with restarts&lt;/strong&gt;. In this &lt;a href=&quot;https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163&quot;&gt;technique&lt;/a&gt;, you periodically make your learning rate very large (and then slowly make it smaller using annealing). The benefit of this technique is that the large learning rates will help you escape the local minima, and hopefully find the global minimum (or at least a good minimum).&lt;/p&gt;

&lt;h3 id=&quot;gradient-descent-in-practice&quot;&gt;Gradient descent in practice&lt;/h3&gt;

&lt;p&gt;In practice, there are other modifications people apply to gradient descent in order to make it faster/easier to compute.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The form of gradient descent described above is known as “batch gradient descent”. This means that the entire dataset is used to compute the gradients. For large datasets this is impractical since the entire dataset needs to fit in memory. In many applications, especially deep learning, &lt;strong&gt;stochastic gradient descent&lt;/strong&gt; (SGD) is used. Instead of using the entire dataset to calculate the gradient, random subsets are used (called mini-batches). While this is slightly less accurate, it is much faster and more efficient.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Momentum&lt;/strong&gt; is a popular addition to SGD since it makes it faster to compute, and typically gives more accurate results. Here you update the weights using the gradient, but you also use a weighted average of the previous gradients. In our example about finding your way down the hill, you would not stop and try to figure out the exact best slope down the hill for each step. You would continue in roughly the same direction and make minor direction changes as needed. Momentum does a similar thing by including the history of gradients in order to speed things up.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;Gradient descent is a technique used in a wide variety of applications. In particular, it is the workhorse of deep learning, and is what is used when a model “learns” weights. It is a fairly simple idea at its core, and hopefully this gave you an intuition for how it works, as well as some techniques that are used in practice.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://wiki.fast.ai/index.php/Gradient_Descent&quot;&gt;An overview of gradient descent with links to more resources&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/5u0jaA3qAGk&quot;&gt;Neural Networks Demystified Part 3: Gradient Descent&lt;/a&gt;. This is a really great short video.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/how-do-we-train-neural-networks-edd985562b73&quot;&gt;How do we ‘train’ neural networks ?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d&quot;&gt;Stochastic Gradient Descent with momentum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">As I’ve said many times before AI/machine learning/deep learning is not magic. In the case of supervised learning models (including deep learning) you have four things:</summary></entry><entry><title type="html">F is for F1 score</title><link href="https://abcsofdatascience.ca/blog/f-is-for-f1" rel="alternate" type="text/html" title="F is for F1 score" /><published>2020-05-20T00:00:00-05:00</published><updated>2020-05-20T00:00:00-05:00</updated><id>https://abcsofdatascience.ca/blog/f-is-for-f1-score</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/f-is-for-f1">&lt;p&gt;When we are training supervised learning models, we want to measure how well the model is performing. Choosing the correct metric for measuring model performance depends on what kind of task you are doing. There are two main categories of supervised learning tasks&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Classification: Here you are trying to predict which category (or categories) a piece of input data belongs to. For example, given an image you might try to predict if it is a picture of a dog or cat.&lt;/li&gt;
  &lt;li&gt;Regression: Here you are trying to predict a numerical label. For example, you might try to predict the selling price of a house given some features about it, such as neighbourhood, number of bedrooms etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this blog I’ll cover a couple of different methods for measuring model performance. First we’ll focus on classification tasks. To make this more concrete let’s imagine we are training a model to predict if a cookie contains either chocolate chips or raisins.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/f_is_for_f1/cookie_class_small.png&quot; alt=&quot;&quot; title=&quot;Taken from https://commons.wikimedia.org/wiki/File:Chocolate_chip_cookies.jpg and https://commons.wikimedia.org/wiki/File:Raisin_cookie.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-problem-with-accuracy&quot;&gt;The problem with accuracy&lt;/h3&gt;

&lt;p&gt;One way of measuring model performance is called classification accuracy (more commonly referred to as accuracy). This is simply “how many predictions did you get correct out of how many predictions did you make?”. If you correctly predicted the type of cookie 95 times out of 100 predictions, your accuracy would be 95%. However, accuracy only works well if the number of items in each category is roughly equal. If there are many more items in some categories than others, we call this &lt;strong&gt;class imbalance&lt;/strong&gt;. For example, chocolate chip cookies are much more popular than raisin cookies in general. If we assume out of 100 random cookies that 99 of them are chocolate chip, we could get 99% accuracy by guessing chocolate chip every single time. In practice this would be a pretty terrible model, but according to accuracy this is a good model.&lt;/p&gt;

&lt;h3 id=&quot;building-a-confusion-matrix&quot;&gt;Building a confusion matrix&lt;/h3&gt;

&lt;p&gt;If we want to try to address this problem we can try building a &lt;strong&gt;confusion matrix&lt;/strong&gt; (which is less scary/confusing than it sounds). A confusion matrix shows all of the possible combinations of predictions vs the actual labels. We need to pick one category as the “positive class” and the other as the “negative class”. This is arbitrary, so let’s pick chocolate chips as the positive class, and raisin as the negative class. There is a sample confusion matrix shown below.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Predicted: Chocolate chip&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Predicted: Raisin&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Actual: Chocolate chip&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;120 (&lt;strong&gt;True Positives&lt;/strong&gt;)&lt;/td&gt;
      &lt;td&gt;2 (&lt;strong&gt;False Negatives&lt;/strong&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Actual: Raisin&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;10 (&lt;strong&gt;False Positives&lt;/strong&gt;)&lt;/td&gt;
      &lt;td&gt;23 (&lt;strong&gt;True Negatives&lt;/strong&gt;)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;I’m sure we’ve all had the experience of picking up what we thought was a chocolate chip cookie. Upon biting into it we realize “ugh, &lt;em&gt;raisin&lt;/em&gt;”. Don’t get me wrong, I like raisin cookies but it is the mismatch between expectation and reality that is the problem. This mismatch is referred to as a &lt;strong&gt;false positive&lt;/strong&gt; (FP) since we predicted the positive class, but it was actually the negative class. As you would expect, there are also &lt;em&gt;false negatives&lt;/em&gt; (FN) where you predict raisin, but it’s actually chocolate chip. If the prediction matches the actual label, these are referred to as &lt;strong&gt;true positives&lt;/strong&gt; (TP) or &lt;strong&gt;true negatives&lt;/strong&gt; (TN).&lt;/p&gt;

&lt;h3 id=&quot;precision-and-recall&quot;&gt;Precision and recall&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt; and &lt;strong&gt;recall&lt;/strong&gt; are ways of measuring classification quality.&lt;/p&gt;

&lt;h5 id=&quot;precision&quot;&gt;Precision&lt;/h5&gt;

&lt;p&gt;$ \text{Precision} = \frac{TP}{TP + FP}$&lt;/p&gt;

&lt;p&gt;This is the number of true positives, divided by all of the positive results predicted by the model.
In our cookie example, this means “when you predicted chocolate chip, how likely was it to actually be chocolate chip?” If we look at the confusion matrix above, the precision would be&lt;/p&gt;

&lt;p&gt;$ \text{Precision} = \frac{120}{120 + 10} = 0.923$&lt;/p&gt;

&lt;h5 id=&quot;recall&quot;&gt;Recall&lt;/h5&gt;

&lt;p&gt;$ \text{Recall}= \frac{TP}{TP + FN}$&lt;/p&gt;

&lt;p&gt;This is the number of true positives, divided by all of the points that should have been classified as positive. More concretely, this is “out of all of the chocolate chip cookies, how many did you find?”&lt;/p&gt;

&lt;p&gt;$ \text{Recall} = \frac{120}{120 + 2} = 0.984$&lt;/p&gt;

&lt;h3 id=&quot;f1-score&quot;&gt;F1 score&lt;/h3&gt;

&lt;p&gt;A model with high precision but low recall, returns few results but the predictions generally correspond to the actual labels. On the other side, a model with high recall but low precision returns many results, but most of the predictions are incorrect when compared to the labelled data. Obviously, we would like a model with both high precision and high recall. A metric called &lt;strong&gt;F1 score&lt;/strong&gt; combines both precision and recall, and it is a common way to measure model performance&lt;/p&gt;

&lt;p&gt;$F1 = 2\frac{P \cdot R}{P+R}$&lt;/p&gt;

&lt;p&gt;An F1 score of 1.0 corresponds to perfect precision and recall and is close to zero for an extremely bad model. The F1 score is just one way of combining precision and recall, and there are &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;other F measures&lt;/a&gt; which weight precision/recall differently.&lt;/p&gt;

&lt;h3 id=&quot;things-to-consider&quot;&gt;Things to consider&lt;/h3&gt;

&lt;p&gt;In some problems, false positives are more important than false negatives. In others, the opposite is true. Imagine we are trying to predict if a patient has a certain disease or not. A false positive means we think they have the disease, but in actuality they are healthy. Depending on the side effects of treatment, a wrong prediction could have severe consequences. If there are major side effects to treating the disease, we may want to favour precision over recall. On the other hand, there may be cases where treating the disease has minor side effects, and leaving the disease untreated has major consequences. In this case we would want to favour recall, where we find as many instances of the disease as possible. This is obviously a complicated subject, and I highly recommend listening to &lt;a href=&quot;http://lineardigressions.com/episodes/2019/12/22/data-scientists-beware-of-simple-metrics&quot;&gt;this episode of the podcast linear digressions&lt;/a&gt; if you want to know more.&lt;/p&gt;

&lt;h3 id=&quot;regression&quot;&gt;Regression&lt;/h3&gt;

&lt;p&gt;Now we’ll briefly talk about measuring the performance of regression models. Let’s imagine we have a model which predicts the selling price of a house based on it’s square footage. Here we don’t have a small number of categories (e.g. a house could sell for &lt;span&gt;$&lt;/span&gt;503 200 or &lt;span&gt;$&lt;/span&gt;632 777). Below I’ve plotted some fake data where the black points show the predicted price, and the blue points show the actual selling price. One way of measuring the amount of error is called &lt;strong&gt;Mean Absolute Error&lt;/strong&gt; (MAE). This is simply adding up all the differences between the predicted and actual values (shown by the red lines) and dividing by the number of points. The absolute part of MAE just means that you take the absolute value of the differences. If you have one prediction which overestimates the price by &lt;span&gt;$&lt;/span&gt;5000 and another which underestimates by &lt;span&gt;$&lt;/span&gt;5000, the MAE is 10000 (not 0 where the two differences cancel out). A related metric is called &lt;strong&gt;Mean Squared Error&lt;/strong&gt; (MSE) where you square the differences before adding them up. The reason for this that big differences will become even bigger. As an example, a difference of &lt;span&gt;$&lt;/span&gt;2 will become 4 but a difference of &lt;span&gt;$&lt;/span&gt;1000 will become 1000000.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/f_is_for_f1/mean_absolute_error_house_price.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;When working on a supervised learning problem, choosing the correct metric is important. First you should think about if you are working on a classification or regression problem. Then you need to consider which metric best measures what you are trying to achieve. This is just a small summary of some of the ways of measuring model performance. For more info check out the links below or look at the description of cross-entropy loss in &lt;a href=&quot;/blog/d-is-for-deep-learning&quot;&gt;“D is for deep learning”&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234&quot;&gt;Other metrics you can use&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html&quot;&gt;More on precision and recall&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lineardigressions.com/episodes/2019/12/22/data-scientists-beware-of-simple-metrics&quot;&gt;Beware of simple metrics podcast&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">When we are training supervised learning models, we want to measure how well the model is performing. Choosing the correct metric for measuring model performance depends on what kind of task you are doing. There are two main categories of supervised learning tasks</summary></entry><entry><title type="html">E is for Embeddings</title><link href="https://abcsofdatascience.ca/blog/e-is-for-embeddings" rel="alternate" type="text/html" title="E is for Embeddings" /><published>2020-05-03T00:00:00-05:00</published><updated>2020-05-03T00:00:00-05:00</updated><id>https://abcsofdatascience.ca/blog/e-is-for-embeddings</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/e-is-for-embeddings">&lt;p&gt;In supervised learning, we have labels which tells us the group(s) a data point belongs to. However, in unsupervised learning (where we don’t have labels) we need to calculate how similar points are from one another. To do this we need to have an &lt;strong&gt;embedding&lt;/strong&gt; which consists of two things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A numeric representation of your data (because we need to do math)&lt;/li&gt;
  &lt;li&gt;A distance measure (so we can determine how close/far two points are from one another)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each embedding gives you a different way to look at your data, depending on the features/numeric representation and distance measure you choose.&lt;/p&gt;

&lt;h3 id=&quot;lets-solve-a-mystery&quot;&gt;Let’s solve a mystery&lt;/h3&gt;

&lt;p&gt;To give you a better idea about what embeddings are, we’re going to look at people hanging out in the Clue mansion. However, instead of solving a murder mystery, we are going to try to determine groups of friends of people in the mansion.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/e_is_for_embedding/clue_board_with_people.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If I asked you to guess which people (shown as X’s) were most likely to be friends in the image above, you’d probably say the people in the ballroom or lounge. This is because they are physically close together. But how can we say they are “close together”? Implicitly in your head you did this using an embedding. You probably looked at the position of people on the board (i.e their x,y coordinates) so we have a numeric representation of the data. We also know that the people in the ballroom are closer to each other than they are to the person standing outside the billiards room. How do we know this? Imagine drawing a line between the person closest to the piano and the person directly to their left. Now imagine drawing another line between the person closest to the piano, and the person just outside the billiards room. The length of the first line is shorter than the second line, so we say that the two people in the ballroom are closer to each other. This method of measuring distance is called &lt;strong&gt;Euclidean distance&lt;/strong&gt;, and it’s probably what you think of first when you need to determine how close/far something is. However, there are other ways to measure distance.&lt;/p&gt;

&lt;h3 id=&quot;distance-measures&quot;&gt;Distance measures&lt;/h3&gt;

&lt;p&gt;There are many kinds of &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&quot;&gt;distance measures (or metrics)&lt;/a&gt; but here are a few popular/useful ones. I’ll also describe some additional distance metrics in a later blog.&lt;/p&gt;

&lt;h5 id=&quot;euclidean-distance&quot;&gt;Euclidean distance&lt;/h5&gt;
&lt;p&gt;This is just the length of the line drawn directly between two points as we discussed above.&lt;/p&gt;

&lt;h5 id=&quot;manhattancity-block-distance&quot;&gt;Manhattan/city block distance&lt;/h5&gt;
&lt;p&gt;Look at the two people outside the billiards room. If you were playing the game and wanted to move one to the other, you could not move them on a straight line between them. You’d have to move 1 over and then 3 up/down for a total of 4 moves. This is similar to Manhattan (also known as city block) distance, which is the sum of the distances in each direction. In the illustration below, the Manhattan distance between the two points is 12. If you were walking you would need to walk 12 city blocks (assuming you can’t walk through buildings), but there are multiple routes you could take. Manhattan distance is useful for higher dimensional data where Euclidean distance breaks down in what is known as &lt;a href=&quot;https://towardsdatascience.com/the-curse-of-dimensionality-50dc6e49aa1e&quot;&gt;“the curse of dimensionality”&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/e_is_for_embedding/Manhattan_distance_bgiu.png&quot; alt=&quot;&quot; title=&quot;Two points with a Manhattan distance of 12. Taken from https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Manhattan_distance.svg/1200px-Manhattan_distance.svg.png&quot; /&gt;&lt;/p&gt;

&lt;h5 id=&quot;cosine-distancesimilarity&quot;&gt;Cosine distance/similarity&lt;/h5&gt;

&lt;p&gt;Another way we can measure distance is by looking at the cosine of the angles between vectors. To make this more concrete, let’s imagine we have some data on how often people spend time in particular rooms in the mansion.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Billiards room&lt;/th&gt;
      &lt;th&gt;Study&lt;/th&gt;
      &lt;th&gt;Library&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Mr. Green&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ms. Scarlet&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Professor Plum&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In this case, Mr. Green has been in the billiards room 3 times but has never been in the study or library. Looking at these counts we would probably say that Ms. Scarlet and Professor Plum are more similar to each other than they are to Mr. Green. We can think of these counts as vectors in a coordinate system, where instead of an X or a Y axis we have a “Billiards room” or “Study” axis. Below I’ve plotted the vectors below and you can see that the angle between the Ms. Scarlet and Professor Plum vectors is smaller even though the lengths of the vectors are quite different.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/e_is_for_embedding/cosine_example.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cosine distance lets us say that two things are similar if they have similar sets of “stuff” even if the frequencies (i.e. vector lengths) are different. If two vectors are pointing in the exact same direction, the angle between them is 0 degrees (even if the length of the vectors are different). The cosine of 0 is 1, so we say they have a cosine similarity of 1. To convert this to a distance, we do 1-similarity since we want the distance between perfectly similar things to be 0. If two things are completely dissimilar, the angle between them is 90 degrees and the cosine similarity is 0. One benefit of cosine similarity is that it takes the direction of the vectors into account, where two vectors pointing in the exact opposite direction will have a similarity of -1.&lt;/p&gt;

&lt;h3 id=&quot;changing-feature-sets&quot;&gt;Changing feature sets&lt;/h3&gt;

&lt;p&gt;Looking at the physical distance between people in the house is one way to try and determine friend groups. There are other ways that you could measure this. For example you could give everyone a survey about their hobbies/interests. The participants put an X if they are interested in a particular hobby, and leave it blank if they aren’t. This would give you a matrix where a 1 corresponds to a X and a 0 corresponds to a blank:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Board games&lt;/th&gt;
      &lt;th&gt;Baseball&lt;/th&gt;
      &lt;th&gt;Dancing&lt;/th&gt;
      &lt;th&gt;Cooking&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Colonel Mustard&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mrs White&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mrs Peacock&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You could then use cosine distance to determine which people have similar interests to one another. This potentially gives you a different view of your data, where the person in the study is (physically) very far from everyone in the first feature set, but could have interests very similar to other people in the second feature set.&lt;/p&gt;

&lt;h3 id=&quot;things-to-keep-in-mind&quot;&gt;Things to keep in mind&lt;/h3&gt;

&lt;p&gt;All unsupervised machine learning techniques require an embedding. It’s important to think about which feature set/numeric representation and distance metrics you’re using in order to make sure they will help you answer the questions you’re trying to solve. I find it’s helpful to think about “How do I know if two things are similar? What makes them similar?”.&lt;/p&gt;

&lt;p&gt;Many techniques implicitly use a certain distance metric (e.g. k-means clustering uses Euclidean distance). You’ll need to make sure that you’re using a technique that allows you to specify a distance metric, or uses one that is correct for your problem. Additionally, you’ll want to make sure that your features are on the same scale (you may need to do some normalization). For example, if you have some data which includes ratings on a 1-5 scale and other ratings on a 1-100 scale, then that will affect your results. Choosing the right embedding requires thinking about your problem, as well as trying out different feature sets and distance metrics.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=OtVR_ZnXLu4&amp;amp;list=PLGVZCDnMOq0pHVE3SB0ecki__VMncQPKo&amp;amp;index=41&amp;amp;t=0s&quot;&gt;Embed all the things - John Healy (talk from Pydata Los Angeles 2019)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7&quot;&gt;Different Types of Distance Metrics used in Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">In supervised learning, we have labels which tells us the group(s) a data point belongs to. However, in unsupervised learning (where we don’t have labels) we need to calculate how similar points are from one another. To do this we need to have an embedding which consists of two things:</summary></entry><entry><title type="html">D is for Deep Learning</title><link href="https://abcsofdatascience.ca/blog/d-is-for-deep-learning" rel="alternate" type="text/html" title="D is for Deep Learning" /><published>2020-04-08T00:00:00-05:00</published><updated>2020-04-08T00:00:00-05:00</updated><id>https://abcsofdatascience.ca/blog/d-is-for-deep-learning</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/d-is-for-deep-learning">&lt;p&gt;Deep learning is a class of machine learning algorithms that has exploded in popularity in the past decade. It powers many applications including computer vision, voice assistants, and translating text. While many of these applications might seem like magic, deep learning itself is not magic, and the underlying concepts are fairly easy to understand. The goal of this is to give you a high level overview so I’ll be glossing over some of the nitty-gritty details.&lt;/p&gt;

&lt;p&gt;People train and apply deep learning models across a wide variety of problem domains and tasks. One of the most common use cases for deep learning models is &lt;strong&gt;classification&lt;/strong&gt; where you are trying to predict which group of things a piece of data belongs to (e.g. classifying images as a cat or dog). In order to train this model you need to have a label for each image saying that it contains a cat or dog. A machine learning problem where you have labelled data is known as a &lt;strong&gt;supervised learning problem&lt;/strong&gt;. If you don’t have labels then you need to use &lt;a href=&quot;/blog/c-is-for-clustering&quot;&gt;unsupervised techniques&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;distinguishing-between-dogs-and-traffic-cones&quot;&gt;Distinguishing between dogs and traffic cones&lt;/h3&gt;

&lt;p&gt;To make this more concrete let’s use an (admittedly ridiculous) example. Let’s say we have a bunch of pictures, and we want to classify whether the image is of a dog or a traffic cone. This seems pretty simple on the surface because a traffic cone looks nothing like a dog.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d_is_for_deep_learning/dog_and_traffic_cone.png&quot; alt=&quot;&quot; title=&quot;How could you even confuse the two?
Adapted from https://commons.wikimedia.org/wiki/File:Golden_Retriever_puppy_standing.jpg and
https://commons.wikimedia.org/wiki/File:Trafficcone.JPG
&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can probably think of some &lt;strong&gt;features&lt;/strong&gt; that would distinguish these two groups such as:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Is it orange?&lt;/li&gt;
  &lt;li&gt;Is it cone shaped?&lt;/li&gt;
  &lt;li&gt;Does it have fur?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This seems pretty clear cut to me. However, if you search a little bit, you can find some examples where the lines start to blur a little bit.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d_is_for_deep_learning/construction_dog_cone.png&quot; alt=&quot;&quot; title=&quot;Adapted from https://www.pinterest.com/pin/432416001701357917/ and https://commons.wikimedia.org/wiki/File:Golden_retriever_with_Elizabethan_Cone.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In one picture, there &lt;em&gt;is&lt;/em&gt; orange and in the other there &lt;em&gt;is&lt;/em&gt; a cone shape. In both cases however, they are both clearly dogs since they have fur. This means that some features are more/less important than others in being able to distinguish between the two groups (that is they have different weights).&lt;/p&gt;

&lt;p&gt;So if we want to be able to effectively predict if an image is of a dog or a traffic cone, we need two things:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Features&lt;/li&gt;
  &lt;li&gt;A way to weight those features&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It is challenging to come up with features and encode them into our program. For example, how would you code “this image has fur in it”? Even if we can code our features, it’s hard to be sure that they are useful in distinguishing between our groups of images. The appeal of deep learning is that it learns both the features and the weights. Typically, there are a large number of features and weights (way more than you would want to come up with manually), which is why things like GPUs are used to train deep learning models. We’ll go through this in more detail in the next section.&lt;/p&gt;

&lt;h3 id=&quot;how-does-deep-learning-actually-work&quot;&gt;How does deep learning actually work?&lt;/h3&gt;

&lt;p&gt;Deep learning typically refers to large artificial neural network models. A neural network consists of multiple “neurons”. Each circle in the image below is a neuron. The neurons are grouped into  layers, classified as input, hidden, or output layers. The “deep” part of deep learning means that there are many hidden layers in the model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d_is_for_deep_learning/neural_net_with_dog.png&quot; alt=&quot;&quot; title=&quot;Adapted from https://commons.wikimedia.org/wiki/File:Artificial_neural_network.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At a very high level, the input layer derives features from the data that you pass into it. The arrows connecting the layers are referred to as weights. The first hidden layer then receives the features from the input layer, multiplied by the weights between the two layers. If there are multiple hidden layers, then the first layer acts as an input layer for the second layer and so on. Finally, it goes to the output layer where the neural network makes predictions about the input data (e.g. is it a dog or a traffic cone). There is one neuron in the output layer for each class we are trying to predict. We can compare these predictions to their actual labels (e.g. the model predicted the image was a traffic cone but it was actually a dog). Each prediction also has a probability associated with it (e.g. “I am 99% sure this is a dog”). How you actually compare the predicted and actual labels is known as the &lt;strong&gt;objective function&lt;/strong&gt; (sometimes referred to as a cost or loss function). We can use this objective function to update the weights in our model (using something called backpropagation). We repeat this process over and over again until we are satisfied with the model performance. This process is known as “training” a model.&lt;/p&gt;

&lt;p&gt;The exact specifics of what makes up the layers is referred to as the network &lt;strong&gt;architecture&lt;/strong&gt;. People generally choose a class of architecture based on the type of problem they are dealing with. For example, if you have image data you will typically choose a class of NNs called convolutional neural networks (CNNs). Within that general group of CNNs, people typically use a predefined architecture such as ResNet. If you have text data, you would typically use a class of models called recurrent neural networks (RNNs) or a subcategory of RNNs called long-short term memory networks (LSTMs).&lt;/p&gt;

&lt;p&gt;Let’s go back to our dogs versus traffic cones example. If we wanted to train a model to distinguish between those two classes of images, we need to choose a couple of things&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A model architecture&lt;/li&gt;
  &lt;li&gt;An objective function&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Since we are dealing with images we will choose some flavour of CNN for our architecture. For the objective function we will choose something called “cross entropy loss”. Cross entropy loss not only measures if the prediction was correct or not but includes how confident the model was. In the case of cross entropy loss a lower number is better. It gives a high value if you are confident and wrong but penalizes you less if you are wrong but less sure about your prediction. Conversely, if you are confident and correct then the value of the loss function will be low.
For example, if the model was very confident (e.g. 99% confident) that the picture was a dog but if it was a traffic cone then the value of the loss would be high.&lt;/p&gt;

&lt;p&gt;Once we choose an architecture and an objective function, we can train the model. The weights in the model are typically initialized at random. You can also use weights from a pre-trained model (this is known as transfer learning and will be discussed in a later blog). Training uses the labels and objective function to learn/update the weights in order to improve the predictions. I’ll talk about how the weights are actually updated (using something called backpropagation/gradient descent) in a later blog.&lt;/p&gt;

&lt;p&gt;You might be wondering “what if there is a picture which contains a dog and a traffic cone?” This is referred to as multi-label classification where you are trying to predict all labels associated with some given input data (e.g. an image). This works in the same way, just with a different objective function.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d_is_for_deep_learning/dog_with_traffic_cone_same_picture.jpg&quot; alt=&quot;&quot; title=&quot;Taken from https://www.flickr.com/photos/rsmith11235/8756198755&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;doing-this-in-practice&quot;&gt;Doing this in practice&lt;/h3&gt;

&lt;p&gt;If you want to learn more about deep learning and have some experience with python, I recommend taking fast.ai’s &lt;a href=&quot;https://course.fast.ai/&quot;&gt;practical deep learning for coders course&lt;/a&gt;. It uses a “top-down” approach in which you learn to build and train models first, learning about each component as you need to.&lt;/p&gt;

&lt;p&gt;If you actually want to implement a deep learning model, you should use an existing framework. Some popular python frameworks are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.tensorflow.org/#&quot;&gt;Tensorflow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pytorch.org/&quot;&gt;Pytorch&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://keras.io/&quot;&gt;Keras&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/fastai/fastai&quot;&gt;Fastai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.coursera.org/specializations/deep-learning&quot;&gt;Deep learning specialization on Coursera&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://course.fast.ai/part2&quot;&gt;Deep learning from the foundations&lt;/a&gt; (part 2 of the fastai course)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=oV3ZY6tJiA0&quot;&gt;Neural Networks and Deep Learning: Crash Course AI #3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Deep learning is a class of machine learning algorithms that has exploded in popularity in the past decade. It powers many applications including computer vision, voice assistants, and translating text. While many of these applications might seem like magic, deep learning itself is not magic, and the underlying concepts are fairly easy to understand. The goal of this is to give you a high level overview so I’ll be glossing over some of the nitty-gritty details.</summary></entry><entry><title type="html">C is for Clustering</title><link href="https://abcsofdatascience.ca/blog/c-is-for-clustering" rel="alternate" type="text/html" title="C is for Clustering" /><published>2020-03-01T00:00:00-06:00</published><updated>2020-03-01T00:00:00-06:00</updated><id>https://abcsofdatascience.ca/blog/c-is-for-clustering</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/c-is-for-clustering">&lt;p&gt;Clustering is useful when you want to find groups of related items. For example, these items could be documents, malware samples, or customers. Clustering is also referred to as unsupervised learning since it does not involve labelled data. High quality labelled data is often hard to get, so clustering is often a good method to analyze your data. We often use clustering methods (along with visualization) when doing exploratory data analysis (EDA) since it allows us to understand how the data clumps together.&lt;/p&gt;

&lt;h3 id=&quot;what-else-can-you-use-clustering-for&quot;&gt;What else can you use clustering for?&lt;/h3&gt;

&lt;h5 id=&quot;anomalyoutlier-detection&quot;&gt;Anomaly/outlier detection&lt;/h5&gt;
&lt;p&gt;Since you know which group an object belongs to, you can say “show me the items which don’t belong to a group”. You can also look for points on the outer edges of clusters since they may also be anomalous.&lt;/p&gt;

&lt;h5 id=&quot;labelling-points&quot;&gt;Labelling points&lt;/h5&gt;

&lt;p&gt;You can even use clustering to help you label your data! Instead of labelling 100 images as dogs/cats individually, you could have groups of images which are much easier to label (i.e. “here are 24 dogs all grouped together”).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/dogs_and_cats_labels_smaller.png&quot; alt=&quot;&quot; title=&quot;Is this just an excuse to post cute animal pictures? Maybe.&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-do-you-actually-cluster-points-together&quot;&gt;How do you actually cluster points together?&lt;/h3&gt;

&lt;p&gt;Take a look at the image below (courtesy of &lt;a href=&quot;https://twitter.com/leland_mcinnes&quot;&gt;Leland Mcinnes&lt;/a&gt;). You can probably see which points should be grouped together but some points clearly look like they don’t belong to any groups.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/comparing_clustering_algorithms_unclustered.png&quot; alt=&quot;&quot; title=&quot;Taken from https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The simple definition of clustering “find similar groups of stuff” sounds fairly simple at the surface. If you think about it a bit more you’ll realize that there are a number of questions that need to be answered:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;How do you define similarity?&lt;/em&gt; In every clustering algorithm you need to specify a way of measuring the distance between two points. This is often referred to as a &lt;strong&gt;distance metric&lt;/strong&gt;. As you would expect, points are similar if they are close together (the distance between them is small) and less similar the farther apart they are. There are many kinds of distance metrics, which I will touch on in later blog posts.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Does every point need to belong to a group? Can a point belong to multiple groups?&lt;/em&gt; The answers to these questions depend on the algorithm. In some cases, points can only belong to one group. This is known as &lt;strong&gt;hard clustering&lt;/strong&gt;. In other cases they have a probability associated with being part of a cluster. This is known as &lt;strong&gt;soft clustering&lt;/strong&gt; (or fuzzy clustering). Some clustering algorithms will force every point into a group (whether it belongs in there or not), while others will just label those points as outliers/noise.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;types-of-clustering-methods&quot;&gt;Types of clustering methods&lt;/h3&gt;

&lt;p&gt;Since the definition of cluster is so broad, there are many types of clustering algorithms. Here are a few broad categories:&lt;/p&gt;

&lt;h5 id=&quot;centroid-based&quot;&gt;Centroid based&lt;/h5&gt;

&lt;p&gt;In these algorithms, clusters are determined based on which centroid you are closest to. A centroid is just a point calculated by averaging all of the other points in a group. One popular centroid based method is k-means which works as follows.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pick &lt;em&gt;k&lt;/em&gt; centroids (where k is the number of clusters in your data). For the sake of argument, let’s say we have 2 centroids.&lt;/li&gt;
  &lt;li&gt;Randomly place the centroids&lt;/li&gt;
  &lt;li&gt;Calculate the distance from each point to the centroid, and pick the closest centroid as its cluster id. For example if a point is closest to centroid 1 then it is part of cluster 1&lt;/li&gt;
  &lt;li&gt;Recalculate the centroids as the average of all of the points in the cluster. Centroid 1 is now the average of all points in cluster 1, centroid 2 the average of all points in cluster 2, etc.&lt;/li&gt;
  &lt;li&gt;Repeat steps 3 and 4 until your clusters stabilize (i.e. the cluster ids for your points stop changing)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/kmeansViz.png&quot; alt=&quot;&quot; title=&quot;Taken from https://stanford.edu/~cpiech/cs221/img/kmeansViz.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are a few issues with this method. The first is that it is really hard to know how many clusters you have ahead of time (i.e it’s hard to choose k). The second is that it doesn’t allow for clusters of different shapes since it assumes that all clusters are spherical. Finally, every point is forced into a cluster.&lt;/p&gt;

&lt;h5 id=&quot;density-based&quot;&gt;Density based&lt;/h5&gt;

&lt;p&gt;In density based clustering algorithms, clusters are areas with lots of points. If you look at the image above, this probably closely aligns with your intuition about what is/is not in a cluster. The clusters you identified have high density (lots of points in a small area). &lt;a href=&quot;(https://en.wikipedia.org/wiki/DBSCAN)&quot;&gt;DBSCAN&lt;/a&gt; (density-based spatial clustering of applications with noise) is a popular density based clustering algorithm. It has two main parameters, min_points and epsilon. In order for something to be labelled a cluster, there must be at least min_points close together. If min_points is 10, that means there will be no clusters with less than 10 data points. Epsilon is basically “how far from a point do I look to see if it is close”. For each point, you can see how many other points are within epsilon. If there are at least min_points, then you have a cluster. In the image below, all of the red points (A) have at least 4 points (min_points=4) within epsilon distance. The yellow points (B and C) are also in the cluster because they are reachable from one of the red points. N would be labelled an outlier since it is not within epsilon of any points.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/600px-DBSCAN-Illustration.svg.png&quot; alt=&quot;&quot; title=&quot;Taken from https://en.wikipedia.org/wiki/File:DBSCAN-Illustration.svg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Choosing min_points is much easier than choosing the number of clusters ahead of time (which we needed to do in k-means). However, picking the correct value for epsilon can be tricky and is more of an art than a science. Another issue with DBSCAN is that it assumes all of the clusters have the same density, which is not always the case.&lt;/p&gt;

&lt;h5 id=&quot;distribution-based&quot;&gt;Distribution based&lt;/h5&gt;

&lt;p&gt;In these algorithms, you train sets of statistical models and points are assigned to a cluster based on which model they are most likely to occur in. One benefit of this type of algorithm is each point has a probability associated with belonging (e.g. 0.75 probability of being in cluster A, and a 0.25 probability of being in cluster B). This means soft clustering is baked into the algorithm, and if you want hard clusters (i.e. a point can only belong to one cluster) you can just choose the largest likelihood. One popular algorithm in this class is Gaussian Mixture Models, where you start with a set of randomly initialized Gaussian models and then update their parameters based on your data. Learning these parameters is done using an interative method called [expectation-maximization algorithm(https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm). One downside of these types of models is that they may overfit your data. That is the model will fit your data very well but not generalize well to new data.&lt;/p&gt;

&lt;h5 id=&quot;connectivity-based&quot;&gt;Connectivity based&lt;/h5&gt;

&lt;p&gt;Connectivity based clustering is also known as hierarchical clustering. One of the core ideas is that things can be grouped together at different levels. For example a picture of a golden retriever could be grouped with other retriever breeds, all dogs, common pets, all animals, etc. In this case other pictures of retrievers would be close, other dogs slightly further away, and then other animals further away from that. This creates a dendrogram (tree) and the clusters are determined by where you cut in the tree. For example in the figure if you cut at the first branch, you would have two clusters: one containing lemurs, and the other containing all of the pictures of cats/dogs. Cutting at the next branch down you would have three clusters: lemurs, cats, and all dogs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/c_is_for_clustering/hierarchical_clustering.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are basically two ways to create this dendrogram. The first is a bottom up approach where every point starts as its own cluster and then you merge clusters together. In the second method everything starts as its own cluster and then you iteratively break everything apart until each point is it’s own cluster. The difference between algorithms in this class basically differ on how you choose to measure the distance between clusters.&lt;/p&gt;

&lt;h3 id=&quot;how-do-i-choose-which-clustering-or-class-of-algorithm-to-use&quot;&gt;How do I choose which clustering (or class of) algorithm to use?&lt;/h3&gt;

&lt;p&gt;Some of this depends on your data. In practice many algorithms combine elements of these classes. One example of this is &lt;a href=&quot;https://hdbscan.readthedocs.io/en/latest/&quot;&gt;HDBSCAN&lt;/a&gt; (hierarchical DBSCAN), which is an extremely useful clustering algorithm. I’ll talk about HDBSCAN in more detail in a future blog post but HDBSCAN is a good first choice. If you’re looking for a comparison of different clustering algorithms on the sample data I showed above, take a look at the link “Comparing clustering algorithms” in the resources below.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html&quot;&gt;Comparing clustering algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ayZQj4llUSU&quot;&gt;Clustering: a guide for the perplexed&lt;/a&gt; - John Healy and Leland Mcinnes&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=JnnaDNNb380&amp;amp;list=PL8dPuuaLjXtO65LeD2p4_Sb5XQ51par_b&amp;amp;index=7&quot;&gt;Crash course AI: unsupervised learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Clustering is useful when you want to find groups of related items. For example, these items could be documents, malware samples, or customers. Clustering is also referred to as unsupervised learning since it does not involve labelled data. High quality labelled data is often hard to get, so clustering is often a good method to analyze your data. We often use clustering methods (along with visualization) when doing exploratory data analysis (EDA) since it allows us to understand how the data clumps together.</summary></entry><entry><title type="html">B is for Bias</title><link href="https://abcsofdatascience.ca/blog/b-is-for-bias" rel="alternate" type="text/html" title="B is for Bias" /><published>2020-02-01T00:00:00-06:00</published><updated>2020-02-01T00:00:00-06:00</updated><id>https://abcsofdatascience.ca/blog/b-is-for-bias</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/b-is-for-bias">&lt;p&gt;The term bias is used in a few different contexts within data science. When people mention bias they are typically referring to either the “bias-variance tradeoff” or “unjust bias”. I’ll primarily talk about unjust bias in this blog and will talk about tuning models/measuring model performance in later blogs.&lt;/p&gt;

&lt;h3 id=&quot;bias-variance-tradeoff&quot;&gt;Bias-variance tradeoff&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff&quot;&gt;bias-variance tradeoff&lt;/a&gt; refers to tuning models such that they don’t under/overfit your data. A model has high bias if it underfits the training set (e.g. if you are trying to fit a line to non-linear data). A model has high variance if it overfits the training set (i.e. doesn’t generalize well). This could occur if you have a huge non-linear function with a large number of parameters. The bias-variance tradeoff is trying to find a model that minimizes both of these phenomena.&lt;/p&gt;

&lt;h3 id=&quot;unjust-bias-and-the-importance-of-having-a-human-in-the-loop&quot;&gt;Unjust bias and the importance of having a human in the loop&lt;/h3&gt;

&lt;p&gt;Machine learning models are useful for helping humans sort through large piles of data. However, it is critical to have a human in the loop in order to validate predictions. It’s particularly important when ML models are used to predict things like university admissions or welfare benefits which have a huge impact on people’s lives. As we talked about in the previous blog, there are two key points to always keep in mind about AI/ML&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It’s not magic&lt;/li&gt;
  &lt;li&gt;It’s not perfect&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Problems arise when people treat the output of ML models as completely objective (or magic) with no opportunities to overrule these predictions.&lt;/p&gt;

&lt;p&gt;Bias refers to a model that is prejudiced in favour of particular categories. Unjust bias occurs when there is a mismatch between the models view of the world and how we think the world should be. There are many reasons that this can happen but two of the big ones are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The training data is not truly representative. It may favour certain categories over others leading to better predictions on those categories. As the saying goes: “garbage in, garbage out”.&lt;/li&gt;
  &lt;li&gt;The training data is truly representative of past behaviour. However, this might be different than what we want the future behaviour to be.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are a couple of famous examples of biased models which demonstrate this behaviour.&lt;/p&gt;

&lt;h3 id=&quot;facial-recognition&quot;&gt;Facial recognition&lt;/h3&gt;

&lt;p&gt;Facial recognition tools are increasingly being utilized by organizations such as law enforcement agencies. Model fairness is critical in this case since if a model is biased against particular subgroups it will have a disproportionate impact on the lives of people in that subgroup.
Researchers studied 3 commercially available facial recognition tools from Microsoft, IBM, and FACE++ (study is &lt;a href=&quot;http://gendershades.org/&quot;&gt;here&lt;/a&gt;). The researchers found that the models performed much better on men and also had higher accuracy on lighter skinned people. In the worst case there was a 34.4% difference in accuracy between lighter skinned men compared to darker skinned women. This shows when the training data does not accurately represent all subgroups the result is a biased model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/b_is_for_bias/gendershades.png&quot; alt=&quot;&quot; title=&quot;Taken from http://gendershages.org&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;amazons-hiring-model&quot;&gt;Amazon’s hiring model&lt;/h3&gt;

&lt;p&gt;Like many companies, Amazon receives huge numbers of applicants and sorting through these applications is incredibly time intensive. They had a historical set of applications and know which of those candidates were hired. So, they developed a machine learning model to sort through the applications and rank the candidates in terms of their likelihood to be hired. However, this essentially turned into a gender detection model since the vast majority of their previous hires were men. For example, the model would penalize resumes which included the word “women’s”. This is a case where a model can make accurate predictions based on historical data, however this does not match with how hiring should be done. Despite the fact that Amazon scrapped this model, they are far from the only company who would like to automate portions of their hiring process. Creating a fair and unbiased method of doing so that is interpretable is still an open research question. You should be suspicious of anyone who claims to have solved this problem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://imgs.xkcd.com/comics/ai_hiring_algorithm.png&quot; alt=&quot;&quot; title=&quot;So glad Kate over in R&amp;amp;D pushed for using the AlgoMaxAnalyzer to look into this. Hiring her was a great decisio- waaaait.&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-can-we-fix-this&quot;&gt;How can we fix this?&lt;/h3&gt;

&lt;p&gt;It is important to note that &lt;strong&gt;humans are also biased&lt;/strong&gt;. They can grade using different criteria if they get grumpy or tired. The appeal of using ML models is that they are much cheaper than humans and can scale much better. If left unchecked, this just means that biased decisions are made at a much larger scale than what was done previously. The best approach is to use a mixture of ML models while keeping a human in the loop. This means providing a way for people to appeal decisions made by an ML model (such as university/college admissions) and allowing a human to override the decision. As researchers, something to keep in mind is that the users of these algorithms may not understand probabilities/confidence intervals. Even if they do understand these concepts they may not feel comfortable overruling the ML model.&lt;/p&gt;

&lt;p&gt;Creating models that are fair and interpretable is still an active area of research. This is an incredibly complex and nuanced topic but it is important to be aware of it. Later on, I will write a blog about the different techniques you can use to interpret ML models to try and gain insight into how they are making decisions.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=S-6YGPrmtYc&quot;&gt;Getting Specific About Algorithmic Bias&lt;/a&gt;) - &lt;a href=&quot;https://twitter.com/math_rachel&quot;&gt;Rachel Thomas&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.ca/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815&quot;&gt;Weapons of Math Destruction&lt;/a&gt; - &lt;a href=&quot;https://twitter.com/mathbabedotorg&quot;&gt;Cathy O’Neil&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.ca/Hello-World-Algorithms-Define-Future/dp/039363499X&quot;&gt;Hello World&lt;/a&gt; - &lt;a href=&quot;https://twitter.com/fryrsquared&quot;&gt;Hannah Fry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">The term bias is used in a few different contexts within data science. When people mention bias they are typically referring to either the “bias-variance tradeoff” or “unjust bias”. I’ll primarily talk about unjust bias in this blog and will talk about tuning models/measuring model performance in later blogs.</summary></entry><entry><title type="html">A is for Artificial Intelligence</title><link href="https://abcsofdatascience.ca/blog/a-is-for-ai" rel="alternate" type="text/html" title="A is for Artificial Intelligence" /><published>2020-01-15T00:00:00-06:00</published><updated>2020-01-15T00:00:00-06:00</updated><id>https://abcsofdatascience.ca/blog/a-is-for-ai</id><content type="html" xml:base="https://abcsofdatascience.ca/blog/a-is-for-ai">&lt;p&gt;I was recently in San Francisco and throughout the city there are many, many billboards containing slogans like “Mission Critical AI” and “Enterprise AI”. There is no doubt that usage of the phrase “artificial intelligence” or AI has increased dramatically in recent years. This increased usage has made it difficult to tell what “using AI” even means.&lt;/p&gt;

&lt;h3 id=&quot;so-what-is-ai&quot;&gt;So what is AI?&lt;/h3&gt;

&lt;p&gt;Many people have differing opinions on how to strictly define AI. When people refer to AI this is generally synonymous with machine learning (ML). Since it’s so hard to come up with a definition, let’s define what AI is not:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;AI is not magic&lt;/li&gt;
  &lt;li&gt;AI is not perfect (more on that in &lt;a href=&quot;/blog/b-is-for-bias&quot;&gt;B is for Bias&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It’s hard to come up with a strict definition for AI since the generally agreed upon definition has evolved over time. In the 1980s people called large rule based systems (“expert systems”) AI. These systems required subject matter experts and programmers to define a set of rules. As you can imagine (or remember) this is a very time intensive process and there are lots of edge cases to consider. Nowadays people typically think of deep learning (more on that in D is for Deep Learning) as AI. This requires lots of labeled training data (which often needs to be labeled by experts) but models can learn their own rules about the data.&lt;/p&gt;

&lt;p&gt;In both cases the “intelligence” part of AI is a bit of a misnomer. Another term that has been suggested  is &lt;a href=&quot;https://twitter.com/fchollet/status/1214392496375025664&quot;&gt;“cognitive automation”&lt;/a&gt;. We are trying to teach a machine to perform a set of tasks based on our knowledge of the world. This is different from something that is truly intelligent that can reason about the world and learn abstract concepts. This distinction is important and referred to as “general” versus “narrow” AI.&lt;/p&gt;

&lt;p&gt;General AI (also referred to as strong AI) refers to a machine that is “human-like” (think HAL 9000 or Skynet). As you would expect from the name, it can generalize it’s previous knowledge to new problem domains. This means that It can intelligently perform a wide variety of tasks without needing explicit training data. Voice assistants like Alexa, and Siri seem like they can generalize, but as anyone who has used them knows, they definitely have limits. They tend not to understand context in a way that a human would, and questions may need to be rephrased in order to be interpreted correctly. A true general AI doesn’t currently exist and it will probably be a while before it does.&lt;/p&gt;

&lt;p&gt;Narrow AI (or weak AI) refers to a machine that is good at specific tasks (e.g. image recognition) but can’t generalize to different domains. For example, you could train a machine learning model to distinguish between cats and dogs but it would not be able to answer the question “Where is the best pizza in Ottawa?”. Narrow AI works by using predefined rules or learning from lots of (probably labelled) data.&lt;/p&gt;

&lt;h3 id=&quot;what-is-ai-used-for&quot;&gt;What is AI used for?&lt;/h3&gt;

&lt;p&gt;AI/ML is widely used in a large variety of industries for a number of tasks. This includes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recommending videos on youtube&lt;/li&gt;
  &lt;li&gt;Detecting if a computer has malware&lt;/li&gt;
  &lt;li&gt;Financial trading&lt;/li&gt;
  &lt;li&gt;Helping doctors make diagnoses&lt;/li&gt;
  &lt;li&gt;Voice assistants like Google Assistant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many of these tasks are applications of fields such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computer vision (processing images and audio)&lt;/li&gt;
  &lt;li&gt;Natural Language Processing (NLP)&lt;/li&gt;
  &lt;li&gt;Recommender systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The fact that AI is a buzzword means that it is applied to many different products (even if they don’t include any ML models). This over usage of the term causes many people to twitch when they hear it (and judge people who do use the term). However, it’s important to keep in mind your audience when you are talking about machine learning. Some audiences may not be familiar with specific technical terms (point them at this blog series ;) ) but have heard the term AI.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;AI/ML is a rapidly growing field which is being applied to a large variety of domains. It’s hard to separate what is real from the snake oil. I’m hoping this blog series will give you enough background knowledge to think critically when you hear the term AI and know the limitations of AI/ML models. In the next blog I’ll talk about many of these limitations and how they affect people’s everyday lives.&lt;/p&gt;

&lt;h3 id=&quot;other-resources&quot;&gt;Other resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PL8dPuuaLjXtO65LeD2p4_Sb5XQ51par_b&quot;&gt;Crash Course Artificial Intelligence&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.amazon.ca/Hello-World-Algorithms-Define-Future/dp/039363499X&quot;&gt;Hello World&lt;/a&gt; - &lt;a href=&quot;https://twitter.com/fryrsquared&quot;&gt;Hannah Fry&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">I was recently in San Francisco and throughout the city there are many, many billboards containing slogans like “Mission Critical AI” and “Enterprise AI”. There is no doubt that usage of the phrase “artificial intelligence” or AI has increased dramatically in recent years. This increased usage has made it difficult to tell what “using AI” even means.</summary></entry></feed>